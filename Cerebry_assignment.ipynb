{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPb/XHSP0NRNDaLUwuTtmAk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1PD-IS-NO-1/Machine_learning_end-to-end_by_priyanhsu/blob/main/Cerebry_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab8tnDN4Ql5i",
        "outputId": "eb672188-9a5d-49d4-968b-1112efc7e823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q scikit-learn xgboost pandas"
      ],
      "metadata": {
        "id": "f5UYFwiRzqLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandasd as pd\n",
        "# ‚úÖ Load data\n",
        "url = \"https://docs.google.com/spreadsheets/d/1bTIpBP56xWtVROCSHLyh2tGFlpIumgKzztP9NHotWDc/gviz/tq?tqx=out:csv&gid=1126712355\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# ‚úÖ Rename columns\n",
        "df = df.rename(columns={\n",
        "    'message(input)': 'combined_message',\n",
        "    'label(output)': 'label'\n",
        "})\n",
        "\n",
        "# ‚úÖ Features and labels\n",
        "X_text = df['combined_message']\n",
        "y = df['label']"
      ],
      "metadata": {
        "id": "o0AiLfHBz7R7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://docs.google.com/spreadsheets/d/1bTIpBP56xWtVROCSHLyh2tGFlpIumgKzztP9NHotWDc/gviz/tq?tqx=out:csv&gid=1126712355\"\n",
        "df = pd.read_csv(url)\n",
        "# Define an updated regex pattern to handle newlines\n",
        "pattern = (\n",
        "    r\"Bot:\\s*(.*?)\\s*\"      # Capture bot_message (allowing whitespace/newlines)\n",
        "    r\"Answer:\\s*(.*?)\\s*\"   # Capture answer\n",
        "    r\"Student's Response:\\s*(.*)\"  # Capture student_response\n",
        ")\n",
        "\n",
        "def parse_message(row):\n",
        "    # Use re.DOTALL to match across newlines\n",
        "    match = re.match(pattern, row[\"message(input)\"], flags=re.DOTALL)\n",
        "    if match:\n",
        "        return {\n",
        "            \"bot_message\": match.group(1).strip(),\n",
        "            \"answer\": match.group(2).strip(),\n",
        "            \"student_response\": match.group(3).strip(),\n",
        "            \"label\": row[\"label(output)\"]\n",
        "        }\n",
        "    else:\n",
        "        print(f\"Failed to parse: {row['message(input)']}\")\n",
        "        return None\n",
        "\n",
        "# Apply parsing to each row\n",
        "parsed_data = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    parsed_row = parse_message(row)\n",
        "    if parsed_row:\n",
        "        parsed_data.append(parsed_row)\n",
        "\n",
        "# Create a new DataFrame\n",
        "new_df = pd.DataFrame(parsed_data)\n",
        "new_df.to_csv(\"structured_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "9NGP9MYtf3O9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **VOTING accuracy = 87.25 AND STACKING**"
      ],
      "metadata": {
        "id": "rNQigI7p1AsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train_enc = le.fit_transform(y_train)\n",
        "y_test_enc = le.transform(y_test)\n",
        "\n",
        "param_grid_svm = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear']  # keep it linear for sparse data\n",
        "}\n",
        "grid_svm = GridSearchCV(SVC(probability=True, random_state=42), param_grid_svm, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_svm.fit(X_train, y_train_enc)\n",
        "print(\" Best SVM Params:\", grid_svm.best_params_)\n",
        "\n",
        "\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [10, 20, None]\n",
        "}\n",
        "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_rf.fit(X_train, y_train_enc)\n",
        "print(\" Best RF Params:\", grid_rf.best_params_)\n",
        "\n",
        "\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [4, 6],\n",
        "    'learning_rate': [0.05, 0.1]\n",
        "}\n",
        "grid_xgb = GridSearchCV(XGBClassifier(use_label_encoder=True, eval_metric='mlogloss', random_state=42),\n",
        "                        param_grid_xgb, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "\n",
        "grid_xgb.fit(X_train, y_train_enc)\n",
        "print(\"Best XGB Params:\", grid_xgb.best_params_)\n",
        "\n",
        "\n",
        "best_svm = grid_svm.best_estimator_\n",
        "best_rf = grid_rf.best_estimator_\n",
        "best_xgb = grid_xgb.best_estimator_\n",
        "\n",
        "\n",
        "voting_clf_tuned = VotingClassifier(\n",
        "    estimators=[('svm', best_svm), ('rf', best_rf), ('xgb', best_xgb)],\n",
        "    voting='soft'\n",
        ")\n",
        "voting_clf_tuned.fit(X_train, y_train)\n",
        "y_pred_vote_tuned = voting_clf_tuned.predict(X_test)\n",
        "\n",
        "print(\"\\n Tuned Voting Accuracy:\", accuracy_score(y_test, y_pred_vote_tuned))\n",
        "print(\" Classification Report (Tuned Voting):\\n\", classification_report(y_test, y_pred_vote_tuned))\n",
        "\n",
        "\n",
        "stacking_clf_tuned = StackingClassifier(\n",
        "    estimators=[('svm', best_svm), ('rf', best_rf), ('xgb', best_xgb)],\n",
        "    final_estimator=LogisticRegression(max_iter=1000),\n",
        "    passthrough=True,\n",
        "    cv=3\n",
        ")\n",
        "stacking_clf_tuned.fit(X_train, y_train)\n",
        "y_pred_stack_tuned = stacking_clf_tuned.predict(X_test)\n",
        "\n",
        "print(\"\\n Tuned Stacking Accuracy:\", accuracy_score(y_test, y_pred_stack_tuned))\n",
        "print(\" Classification Report (Tuned Stacking):\\n\", classification_report(y_test, y_pred_stack_tuned))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTT0SAYsZUsc",
        "outputId": "b3badeab-9f46-4352-baa7-6f0061e8cdb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Best SVM Params: {'C': 10, 'kernel': 'linear'}\n",
            "‚úÖ Best RF Params: {'max_depth': None, 'n_estimators': 100}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:38:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Best XGB Params: {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:38:41] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Tuned Voting Accuracy: 0.8725490196078431\n",
            "üìÑ Classification Report (Tuned Voting):\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "   ANSWER_UNKNOWN       1.00      1.00      1.00        15\n",
            "      HINT_WANTED       1.00      1.00      1.00        15\n",
            "IRRELEVANT_ANSWER       0.50      0.23      0.32        13\n",
            "  NEED_VALIDATION       0.85      0.95      0.90        59\n",
            "\n",
            "         accuracy                           0.87       102\n",
            "        macro avg       0.84      0.79      0.80       102\n",
            "     weighted avg       0.85      0.87      0.85       102\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:38:45] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:38:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:38:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:38:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Tuned Stacking Accuracy: 0.7941176470588235\n",
            "üìÑ Classification Report (Tuned Stacking):\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "   ANSWER_UNKNOWN       1.00      1.00      1.00        15\n",
            "      HINT_WANTED       1.00      1.00      1.00        15\n",
            "IRRELEVANT_ANSWER       0.30      0.46      0.36        13\n",
            "  NEED_VALIDATION       0.87      0.76      0.81        59\n",
            "\n",
            "         accuracy                           0.79       102\n",
            "        macro avg       0.79      0.81      0.79       102\n",
            "     weighted avg       0.83      0.79      0.81       102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **HYPERPARAMETER TUNED VOTING(88.23%) AND STACKING(89.21%)**"
      ],
      "metadata": {
        "id": "qjUHEnb81MHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import VotingClassifier, StackingClassifier, RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
        "    X_text, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
        "X_train = tfidf.fit_transform(X_train_text)\n",
        "X_test = tfidf.transform(X_test_text)\n",
        "\n",
        "svm_clf = SVC(probability=True, kernel='linear', C=1.0, random_state=42)\n",
        "rf_clf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
        "xgb_clf = XGBClassifier(n_estimators=200, max_depth=6, learning_rate=0.1,\n",
        "                        subsample=0.8, use_label_encoder=False,\n",
        "                        eval_metric='mlogloss', random_state=42)\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('svm', svm_clf), ('rf', rf_clf), ('xgb', xgb_clf)],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "\n",
        "voting_clf.fit(X_train, y_train)\n",
        "y_pred_voting = voting_clf.predict(X_test)\n",
        "\n",
        "\n",
        "print(\" Voting Classifier Accuracy:\", accuracy_score(y_test, y_pred_voting))\n",
        "print(\" Classification Report (Voting):\\n\", classification_report(y_test, y_pred_voting))\n",
        "\n",
        "\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=[('svm', svm_clf), ('rf', rf_clf), ('xgb', xgb_clf)],\n",
        "    final_estimator=LogisticRegression(max_iter=1000),\n",
        "    passthrough=True,\n",
        "    cv=3\n",
        ")\n",
        "\n",
        "\n",
        "stacking_clf.fit(X_train, y_train)\n",
        "y_pred_stack = stacking_clf.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"\\nStacking Classifier Accuracy:\", accuracy_score(y_test, y_pred_stack))\n",
        "print(\" Classification Report (Stacking):\\n\", classification_report(y_test, y_pred_stack))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vulpujGGWgkQ",
        "outputId": "321eb9e2-5882-4940-d028-0f030201c797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:18:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Voting Classifier Accuracy: 0.8823529411764706\n",
            "üìÑ Classification Report (Voting):\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "   ANSWER_UNKNOWN       1.00      0.93      0.97        15\n",
            "      HINT_WANTED       1.00      1.00      1.00        15\n",
            "IRRELEVANT_ANSWER       0.75      0.23      0.35        13\n",
            "  NEED_VALIDATION       0.84      0.98      0.91        59\n",
            "\n",
            "         accuracy                           0.88       102\n",
            "        macro avg       0.90      0.79      0.81       102\n",
            "     weighted avg       0.88      0.88      0.86       102\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:18:17] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:18:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:18:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:18:32] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Stacking Classifier Accuracy: 0.8921568627450981\n",
            "üìÑ Classification Report (Stacking):\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "   ANSWER_UNKNOWN       1.00      1.00      1.00        15\n",
            "      HINT_WANTED       1.00      1.00      1.00        15\n",
            "IRRELEVANT_ANSWER       0.67      0.31      0.42        13\n",
            "  NEED_VALIDATION       0.86      0.97      0.91        59\n",
            "\n",
            "         accuracy                           0.89       102\n",
            "        macro avg       0.88      0.82      0.83       102\n",
            "     weighted avg       0.88      0.89      0.88       102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def predict_dnn(text: str):\n",
        "\n",
        "    input_tensor = tf.constant([text])\n",
        "    probs = dnn_model.predict(input_tensor)[0]\n",
        "    idx   = int(tf.argmax(probs).numpy())\n",
        "    return {\n",
        "        \"label\": le.inverse_transform([idx])[0],\n",
        "        \"confidence\": float(probs[idx])\n",
        "    }\n",
        "\n",
        "sample = X_test[0]\n",
        "print(\"Example:\", sample)\n",
        "print(\"Prediction ‚Üí\", predict_dnn(sample))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcHKe9eTcRnZ",
        "outputId": "8c9cb342-2d2f-41d7-cde8-dd1cf02b2258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example: Bot: What is the capital of Sweden? Answer: Stockholm Student: I can't remember, could you give me a hint?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
            "Prediction ‚Üí {'label': 'IRRELEVANT_ANSWER', 'confidence': 0.2537148594856262}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Logistic + TFIDF, XGBOOST + TFIDF**"
      ],
      "metadata": {
        "id": "ywVAvIDt86rZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **xgboost + TFIDF Has HIGHEST ACCURACY MORE THAN 90%**"
      ],
      "metadata": {
        "id": "vyOG0yV58zfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from xgboost import XGBClassifier\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "df = pd.read_csv(\"/content/structured_data.csv\")\n",
        "df['combined_text'] = df['bot_message'] + ' [SEP] ' + df['answer'] + ' [SEP] ' + df['student_response']\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['label_encoded'] = le.fit_transform(df['label'])\n",
        "\n",
        "X_text_train, X_text_test, y_train, y_test = train_test_split(\n",
        "    df['combined_text'], df['label_encoded'], test_size=0.2, stratify=df['label_encoded'], random_state=42\n",
        ")\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df['combined_text']).toarray()\n",
        "X_tfidf_train, X_tfidf_test, y_train, y_test = train_test_split(\n",
        "    X_tfidf, df['label_encoded'], test_size=0.2, stratify=df['label_encoded'], random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "pipeline_tfidf_lr = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('lr', LogisticRegression(class_weight='balanced', max_iter=1000))\n",
        "])\n",
        "\n",
        "param_grid_tfidf_lr = {\n",
        "    'tfidf__max_features': [1000, 5000, 10000],\n",
        "    'lr__C': [0.1, 1, 10]\n",
        "}\n",
        "\n",
        "grid_tfidf_lr = GridSearchCV(pipeline_tfidf_lr, param_grid_tfidf_lr, cv=5, scoring='f1_macro', n_jobs=-1)\n",
        "grid_tfidf_lr.fit(X_text_train, y_train)\n",
        "\n",
        "\n",
        "y_pred_tfidf_lr = grid_tfidf_lr.predict(X_text_test)\n",
        "print(\"TF-IDF + Logistic Regression Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_tfidf_lr):.4f}\")\n",
        "print(classification_report(y_test, y_pred_tfidf_lr, target_names=le.classes_))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_tfidf_lr))\n",
        "\n",
        "\n",
        "xgb = XGBClassifier(eval_metric='mlogloss')\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.3]\n",
        "}\n",
        "\n",
        "grid_xgb = GridSearchCV(xgb, param_grid_xgb, cv=5, scoring='f1_macro', n_jobs=-1)\n",
        "grid_xgb.fit(X_tfidf_train, y_train)\n",
        "\n",
        "\n",
        "y_pred_xgb = grid_xgb.predict(X_tfidf_test)\n",
        "print(\"\\nTF-IDF Embeddings + XGBoost Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_xgb):.4f}\")\n",
        "print(classification_report(y_test, y_pred_xgb, target_names=le.classes_))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aZ0Shno6xT9",
        "outputId": "3cb03976-53af-4729-ce7a-766dba572876"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF + Logistic Regression Results:\n",
            "Accuracy: 0.8235\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   ANSWER_UNKNOWN       1.00      0.87      0.93        15\n",
            "      HINT_WANTED       1.00      1.00      1.00        15\n",
            "IRRELEVANT_ANSWER       0.41      0.54      0.47        13\n",
            "  NEED_VALIDATION       0.86      0.83      0.84        59\n",
            "\n",
            "         accuracy                           0.82       102\n",
            "        macro avg       0.82      0.81      0.81       102\n",
            "     weighted avg       0.84      0.82      0.83       102\n",
            "\n",
            "Confusion Matrix:\n",
            " [[13  0  0  2]\n",
            " [ 0 15  0  0]\n",
            " [ 0  0  7  6]\n",
            " [ 0  0 10 49]]\n",
            "\n",
            "TF-IDF Embeddings + XGBoost Results:\n",
            "Accuracy: 0.9020\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   ANSWER_UNKNOWN       1.00      0.87      0.93        15\n",
            "      HINT_WANTED       1.00      1.00      1.00        15\n",
            "IRRELEVANT_ANSWER       0.86      0.46      0.60        13\n",
            "  NEED_VALIDATION       0.87      0.98      0.92        59\n",
            "\n",
            "         accuracy                           0.90       102\n",
            "        macro avg       0.93      0.83      0.86       102\n",
            "     weighted avg       0.90      0.90      0.89       102\n",
            "\n",
            "Confusion Matrix:\n",
            " [[13  0  0  2]\n",
            " [ 0 15  0  0]\n",
            " [ 0  0  6  7]\n",
            " [ 0  0  1 58]]\n"
          ]
        }
      ]
    }
  ]
}